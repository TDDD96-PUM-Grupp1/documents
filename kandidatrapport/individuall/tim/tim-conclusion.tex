\section{Slutsatser}
\label{sec:tim-conclusion}
Här sammanfattas resultaten och diskussionen i formen av att svara på frågeställningarna från avsnitt \ref{subsec:tim-research-questions}.

\subsection*{\ref{tim-fs:1} Hur serialisera deepstream datan som skickas över nätverket?}
Som nämnt tidigare görs ingen direkt komprimering av data när man använder sig av deepstream som server och klient. Data som skickas är i formen av JSON-objekt med blanksteg och tabbar borttagna då detta inte ändrar beteendet hos JSON-objekt.

\subsection*{\ref{tim-fs:2} Under vilka förhållanden är det bättre att använda RPC över event och vice versa?}
Från undersökningen ser det ut som att RPC:s ska användas vid alla lägen eftersom att den tar minst tid att exekvera och därmed ger en kortare responstid. Detta stämmer i fallet då tiden till deepstream servern är väldigt kort och om man vill få ett svar tillbaka, vilket man inte alltid vill. Om användningsområdet är att skicka data till en klient utan att få ett svar, så är rundturstiden troligtvis väldigt snarlik. Dessutom kan events skicka data till inte bara en klient utan flera, vilket är något RPC:s inte kan bidra till. En RPC kan endast hanteras av en klient.

Så om man vill skicka data och få ett svar borde RPC användas. Men om man ska skicka data till flera klienter och inte förvänta sig ett svar tillbaka så borde events användas.

\subsection*{\ref{tim-fs:3} Hur påverkas responsiviteten i nätverket beroende på datastorleken?}
När det gäller responsiviteten med avseende på datastorleken så kunde ingen direkt avvikelse ses. Då datamängden ökade så ökade även svarstiden linjärt med den, vilket leder till att responstiden är proportionerlig med datamängden för att JSON-objekt. Vad som kunde ses dock var att rundturstiden varierade mycket mer när man körde med events gentemot RPC:s. Vad detta kan bero på behövs mer undersökning i.

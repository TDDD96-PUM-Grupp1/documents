\section{Diskussion}
\label{sec:tim-discussion}
Under arbetets gång har flera olika resultat uppstått, vilket ger en bra bild av hur storleken på datan över deepstream påverkar tiden det tar att skicka den. För att få en bättre förståelse av resultaten så diskuteras resultat, metod och hur metoden har påverkat resultatet nedan. 

\subsection{Resultat}
\label{subsec:tim-discussion-results}
Från undersökningen har två olika resultat beskrivits där den ena handlar om hur deepstream komprimerar data och den andra hur deepstream skalar beroende på datastorleken.

\subsubsection{Serialisering}
När det gäller serialiseringen så gör deepstream inga direkta förbättringar för att minska datastorleken, detta beror troligtvis på att Javascript till stor del bygger på JSON-objekt och i och med det finns det en motivering av att fortsätta arbeta med just det formatet. Då behöver inte mycket göras för att omvandla klasser, datastrukturer eller liknande eftersom allt till stor del bygger på JSON och listor.

Frågan är då om deepstream hade tagit nytta av att göra om datan till ett binärt format, vilket enligt avsnitt \ref{sec:tim-background} skulle ge ett bättre resultat. Problemet här är att den binära serialiseringen bygger på att datastrukturen är upplagd på ett visst sätt, och i fallet med Javascript och Protobuf behövs ett helt nytt objekt med setters användas för att skicka datan. Detta kan då leda till att binärdatan får mer overhead för att ens börja serialiseras. Vilket kan visa sig ta längre tid än JSON-objekt, detta skulle dock behövas undersökas vidare för att få ett mer konkret resultat kring serialiseringshastigheter.

\subsubsection{Svarstid}
Från resultatet kunde man se att RPC är snabbare än att använda sig av event när det gäller att skicka och ta emot data. Anledningen till detta kan ligga i att ett event måste kolla upp vilka användare som prenumererar på en viss kanal två gånger. RPCs behöver endast göra detta en gång då den inte behöver leta upp vem som frågade efter RPC:n eftersom denna skickas med i anropet. Utöver det så kan det tillkomma en hel del overhead med events då flera kan lyssna på samma kanal och mer beräkningar behövs då göras, vilket i sin tur kan ge upphov till att spridningen för events är större än för RPC:s. Hur RPC:s och events är implementerade kan ses i källkoden för deepstream på GitHub\footnote{\url{https://github.com/deepstreamIO/deepstream.io} \newline commit: 98a2f53b0f7ca984a0f0f2f5a89c225c21467687}. 

\subsection{Metod}
\label{subsec:tim-discussion-method}
Metoden som har använts har givit en bättre insyn om hur de olika funktionerna RPC och event fungera i en djupare nivå, samt om deepstream gör någon form av komprimering av data. För komprimering och analysen i Wireshark, så speglar metoden exakt på hur datan serialiseras då detta varken beror på CPU-hastighet, nätverk eller andra oförutsägbara parametrar. Så det går direkt att säga deepstream inte använder sig av någon form av komprimering.

Om man dock blickar bort mot responstiden så finns det mycket som kan påverka resultatet, till en början spelar datorns processor roll, då en snabbare processor ger bättre värden. Dock så borde detta inte reflektera över att RPC är snabbare än event då detta borde dra ner responstiden lika mycket. Andra saker som spelar större roll är hur Javascripten exekveras, i termer av hur datastrukturer hanteras på olika processorer. Detta kan ge större påverkningar på resultatet eftersom sättet Javascript hanterade datastrukturen på datorn som användes för undersökningen kanske fungerade bättre för RPC än för event. Detta är något som borde undersökas vidare mellan olika datorer. 

En annan sak som inte reflekteras i resultatet från metoden är att undersökningen endast kördes från och till en lokal dator, så en responstid på < 10 millisekunder är inget man kommer se i verkligheten. Detta eftersom att tiden det tar att skicka datan över ett nätverk inte är inräknat, vilket leder till att det ser ut som att RPC:s har ett stort övertag över events. Men om tiden det tar att skicka data från en punkt till en annan ökar, borde inte skillnaden mellan RPCs och events påverkas, då tiden endast reflekterar serialisering, deserialisering och loopbacktiden i datorn (som kan göra andra former av optimeringar då datan inte skickas över ett nätverk).
